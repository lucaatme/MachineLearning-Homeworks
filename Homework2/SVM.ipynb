{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM for classification, without and with kernels\n",
    "\n",
    "In this notebook we are going to explore the use of Support Vector Machines (SVMs) for image classification. We are going to use the famous MNIST dataset, that is a dataset of handwritten digits. We get the data from mldata.org, that is a public repository for machine learning data.\n",
    "\n",
    "The dataset consists of 70,000 images of handwritten digits (i.e., 0, 1, ... 9). Each image is 28 pixels by 28 pixels and we can think of it as a vector of 28x28 = 784 numbers. Each number is an integer between 0 and 255. For each image we have the corresponding label (i.e., 0, 1, ..., 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the required packages\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix your ID here\n",
    "ID = 1234    #set the seed\n",
    "np.random.seed(ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the dataset. 'data' contains the input, 'target' contains the label. We normalize the data by dividing each value by 255 so that each value is in [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the MNIST dataset and let's normalize the features so that each value is in [0,1]\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "# rescale the data\n",
    "X, y = mnist.data.values / 255., mnist.target.values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now split into training and test. We keep 500 samples in the training set. Make sure that each label is present at least 10 times\n",
    "in training. If it is not, then keep adding permutations to the initial data until this \n",
    "happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and frequencies in training dataset: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype=object),\n",
       " array([42, 55, 53, 53, 46, 50, 49, 51, 48, 53]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag = False\n",
    "\n",
    "while not flag:\n",
    "\n",
    "    permutation = np.random.permutation(X.shape[0])\n",
    "\n",
    "    X = X[permutation]\n",
    "    y = y[permutation]\n",
    "\n",
    "    m_training = 500\n",
    "\n",
    "    X_train, X_test = X[:m_training], X[m_training:]\n",
    "    y_train, y_test = y[:m_training], y[m_training:]\n",
    "\n",
    "    #looping through all elements of y_train and count how many occurrences of each element there are\n",
    "    #if there are at least 10 occurrences of each element, then the flag is set to True and the loop is broken\n",
    "    #otherwise, the flag is set to False and the loop is repeated\n",
    "    \n",
    "    for i in range(10):\n",
    "        if np.count_nonzero(y_train == str(i)) >= 10:\n",
    "            flag = True\n",
    "\n",
    "print(\"Labels and frequencies in training dataset: \")\n",
    "np.unique(y_train, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now provide a function to print an image in the dataset and the corresponding true label given the index of the image in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for plotting a digit and printing the corresponding labe\n",
    "def plot_digit(X_matrix, labels, index):\n",
    "    print(\"INPUT:\")\n",
    "    plt.imshow(\n",
    "        X_matrix[index].reshape(28,28),\n",
    "        cmap          = plt.cm.gray_r,\n",
    "        interpolation = \"nearest\"\n",
    "    )\n",
    "    plt.show()\n",
    "    print(\"LABEL: %s\" % labels[index])\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's print the 100-th image in X_train and the 40,000-th image in X_test and their true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbnUlEQVR4nO3dcWyU9R3H8c8hcBZsTwm2dx21qQ43A4RERaABBKKVZjKxLgNNDJiNoBQmK+rGmLG6jToWO4ydGoljMEWJmzoWiNgNWjCMCQy0Y87hKKMbbRoa7dVai+BvfxAuHi3g77jrt9e+X8mTcM/zfPt8eXy8T388z/0u4JxzAgDAwADrBgAA/RchBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADMDrRs40+eff66jR48qMzNTgUDAuh0AgCfnnNra2pSbm6sBA8491ul1IXT06FHl5eVZtwEAuEANDQ0aMWLEOffpdSGUmZkp6VTzWVlZxt0AAHxFo1Hl5eXF3s/PJWUh9PTTT+sXv/iFGhsbNWrUKK1atUqTJ08+b93pf4LLysoihAAgjX2ZWyopeTBhw4YNWrJkiZYvX659+/Zp8uTJKi4u1pEjR1JxOABAmgqkYhbt8ePH69prr9UzzzwTW3fNNddo1qxZqqioOGdtNBpVKBRSa2srIyEASEM+7+NJHwkdP35ce/fuVVFRUdz6oqIi7dy5s8v+nZ2dikajcQsAoH9IeggdO3ZMJ0+eVE5OTtz6nJwcNTU1ddm/oqJCoVAotvBkHAD0Hyn7sOqZN6Scc93epFq2bJlaW1tjS0NDQ6paAgD0Mkl/Om748OG66KKLuox6mpubu4yOJCkYDCoYDCa7DQBAGkj6SGjw4MG67rrrVF1dHbe+urpahYWFyT4cACCNpeRzQmVlZbr77rt1/fXXa+LEiXruued05MgR3Xvvvak4HAAgTaUkhGbPnq2WlhY99thjamxs1OjRo7V582bl5+en4nAAgDSVks8JXQg+JwQA6c30c0IAAHxZhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwMxA6waAdHfy5Envmueff9675rHHHvOuueyyy7xrJGnFihXeNTNnzkzoWOjfGAkBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwwwSmwBecOHHCu+anP/2pd82jjz7qXZOI//3vfwnVLV++3Ltm4sSJ3jXDhw/3rkHfwkgIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGSYwBb5g9erV3jU9NRnppZde6l1z2WWXJXSsuro675pbbrnFu2bv3r3eNehbGAkBAMwQQgAAM0kPofLycgUCgbglHA4n+zAAgD4gJfeERo0apT/96U+x1xdddFEqDgMASHMpCaGBAwcy+gEAnFdK7gkdPHhQubm5Kigo0Jw5c3To0KGz7tvZ2aloNBq3AAD6h6SH0Pjx47Vu3Tpt2bJFq1evVlNTkwoLC9XS0tLt/hUVFQqFQrElLy8v2S0BAHqppIdQcXGx7rjjDo0ZM0Y33XSTNm3aJElau3Ztt/svW7ZMra2tsaWhoSHZLQEAeqmUf1h16NChGjNmjA4ePNjt9mAwqGAwmOo2AAC9UMo/J9TZ2an33ntPkUgk1YcCAKSZpIfQAw88oNraWtXX1+uvf/2rvvWtbykajWru3LnJPhQAIM0l/Z/j/vvf/+rOO+/UsWPHdPnll2vChAnatWuX8vPzk30oAECaCzjnnHUTXxSNRhUKhdTa2qqsrCzrdpCmPvvss4TqrrrqKu+aRB6mSWQy0vXr13vXDByY2O+ZM2fO9K45efKkd80rr7ziXTNr1izvGvQsn/dx5o4DAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABgJuVfagdYmDx5ckJ1iUxGGgqFvGteeukl75oZM2Z41yRqz5493jWVlZXeNZMmTfKuQd/CSAgAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIZZtNHr3X///d41b7/9dgo66V5ubq53TU/OiJ2I0aNHe9f8+te/TkEn6OsYCQEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADDDBKboUS+99JJ3zVNPPeVd45zzrpGkUCjkXbN27dqEjgWAkRAAwBAhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzTGCKhO3Zs8e75v777/euSXQy0kSsXLnSu2bcuHEp6MRWe3u7d01LS4t3zapVq7xretLdd9/tXTNmzBjvmoED++9bMSMhAIAZQggAYMY7hLZv366ZM2cqNzdXgUBAr7/+etx255zKy8uVm5urjIwMTZ06VQcOHEhWvwCAPsQ7hNrb2zV27FhVVVV1u33lypWqrKxUVVWVdu/erXA4rJtvvlltbW0X3CwAoG/xvhtWXFys4uLibrc557Rq1SotX75cJSUlkk5962ROTo7Wr1+vBQsWXFi3AIA+Jan3hOrr69XU1KSioqLYumAwqBtvvFE7d+7stqazs1PRaDRuAQD0D0kNoaamJklSTk5O3PqcnJzYtjNVVFQoFArFlry8vGS2BADoxVLydFwgEIh77Zzrsu60ZcuWqbW1NbY0NDSkoiUAQC+U1E9IhcNhSadGRJFIJLa+ubm5y+jotGAwqGAwmMw2AABpIqkjoYKCAoXDYVVXV8fWHT9+XLW1tSosLEzmoQAAfYD3SOjjjz/WBx98EHtdX1+v/fv3a9iwYbriiiu0ZMkSrVixQiNHjtTIkSO1YsUKDRkyRHfddVdSGwcApD/vENqzZ4+mTZsWe11WViZJmjt3rn7zm9/ooYceUkdHhxYuXKgPP/xQ48eP15tvvqnMzMzkdQ0A6BMCridnh/wSotGoQqGQWltblZWVZd0OzmH69OneNdu2bUtBJ13Nnz8/obrnnnsuyZ3Y2rFjR0J1S5cu9a7ZvXt3Qsfqa5588knvmu9973sp6MSOz/s4c8cBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwk9ZtVkZ7+9a9/JVRXV1eX5E6698Vv6f2yEpnJuLdraWnxrtmyZUtCx0pkRuwBA/x/p73lllu8a0aMGOFds2vXLu8aKbFr/M9//rN3zcKFC71rBg7sG2/fjIQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCY6Rsz4OGC7NmzJ6G6Y8eOJbmT7j300EPeNRkZGSnoJHl+//vfe9f8+Mc/9q755z//6V0jSVdeeaV3zW9/+1vvmsLCQu+aRHz00UcJ1U2cONG7ZuPGjd41bW1t3jWXXXaZd01vxEgIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGSYwRUKTaSbq1ltv9a4pLS1NQSfJ88EHH3jX3HPPPd41iUxy+dWvftW7RpK2bNniXZPIpKc95dJLL02oLjMzM7mNoAtGQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwwgWkfU19f712zefPmFHTSvUQmhBw0aFAKOkmeyspK75pEJiOdM2eOd83PfvYz7xqpd09Gmohf/vKXCdXt37/fu2bMmDHeNcFg0Lumr2AkBAAwQwgBAMx4h9D27ds1c+ZM5ebmKhAI6PXXX4/bPm/ePAUCgbhlwoQJyeoXANCHeIdQe3u7xo4dq6qqqrPuM2PGDDU2NsaWnrznAABIH94PJhQXF6u4uPic+wSDQYXD4YSbAgD0Dym5J1RTU6Ps7GxdffXVmj9/vpqbm8+6b2dnp6LRaNwCAOgfkh5CxcXFevHFF7V161Y98cQT2r17t6ZPn67Ozs5u96+oqFAoFIoteXl5yW4JANBLJf1zQrNnz479efTo0br++uuVn5+vTZs2qaSkpMv+y5YtU1lZWex1NBoliACgn0j5h1UjkYjy8/N18ODBbrcHg8F+/UEtAOjPUv45oZaWFjU0NCgSiaT6UACANOM9Evr444/1wQcfxF7X19dr//79GjZsmIYNG6by8nLdcccdikQiOnz4sH70ox9p+PDhuv3225PaOAAg/XmH0J49ezRt2rTY69P3c+bOnatnnnlGdXV1WrdunT766CNFIhFNmzZNGzZsSGjOMABA3+YdQlOnTpVz7qzbt2zZckEN4cJ0dHR413z66acp6KR7gwcP7rFjJaKpqcm75tlnn01BJ12VlpZ61/T2iUjP9tTsuTz99NPeNUuXLvWukXTO97qzefDBB71rhgwZ4l3TVzB3HADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADATMq/WRU9a9WqVdYtnNP3v/996xbOKSsry7vmpptu8q6prq72rvnjH//oXTN+/HjvGkkaNGiQd82///1v75pEvmesrq7OuyZRP/jBD7xrvvnNb6agk76LkRAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzTGDai3V0dHjXvPPOOynopP8YMmSId80rr7ziXfPd737Xu+bNN9/0rvn2t7/tXSNJf/vb37xrFixY4F3jnPOuufjii71rHn74Ye8aKbG/UygUSuhY/RUjIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGaYwLQXy8jI8K4ZO3asd83bb7/tXZOoqqoq75qnnnrKuyaRSS4TNXCg//9G9913n3fNCy+84F1zzz33eNdIUl1dXUJ1vr72ta951zz44IPeNd/5zne8a9AzGAkBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwE3DOOesmvigajSoUCqm1tVVZWVnW7aSdHTt2eNdMmTIlBZ0kTyKTsg4ePDgFnXSvo6PDu+bvf/97CjqxNWfOHO+aJ5980rsmOzvbuwY9y+d9nJEQAMAMIQQAMOMVQhUVFRo3bpwyMzOVnZ2tWbNm6f3334/bxzmn8vJy5ebmKiMjQ1OnTtWBAweS2jQAoG/wCqHa2lqVlpZq165dqq6u1okTJ1RUVKT29vbYPitXrlRlZaWqqqq0e/duhcNh3XzzzWpra0t68wCA9Ob1lZBvvPFG3Os1a9YoOztbe/fu1ZQpU+Sc06pVq7R8+XKVlJRIktauXaucnBytX79eCxYsSF7nAIC0d0H3hFpbWyVJw4YNkyTV19erqalJRUVFsX2CwaBuvPFG7dy5s9uf0dnZqWg0GrcAAPqHhEPIOaeysjJNmjRJo0ePliQ1NTVJknJycuL2zcnJiW07U0VFhUKhUGzJy8tLtCUAQJpJOIQWLVqkd999Vy+99FKXbYFAIO61c67LutOWLVum1tbW2NLQ0JBoSwCANON1T+i0xYsXa+PGjdq+fbtGjBgRWx8OhyWdGhFFIpHY+ubm5i6jo9OCwaCCwWAibQAA0pzXSMg5p0WLFunVV1/V1q1bVVBQELe9oKBA4XBY1dXVsXXHjx9XbW2tCgsLk9MxAKDP8BoJlZaWav369frDH/6gzMzM2H2eUCikjIwMBQIBLVmyRCtWrNDIkSM1cuRIrVixQkOGDNFdd92Vkr8AACB9eYXQM888I0maOnVq3Po1a9Zo3rx5kqSHHnpIHR0dWrhwoT788EONHz9eb775pjIzM5PSMACg72AC0z7ms88+8655+OGHEzrWz3/+84TqkJj8/HzvmrKysoSO9Y1vfMO75sorr/SuOdsDS0hvTGAKAEgLhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzzKINnThxIqG6d955x7vmd7/7XULH8lVZWZlQ3aRJk7xrbrjhBu+akpIS75prrrnGu+aSSy7xrgEuFLNoAwDSAiEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADNMYAoASComMAUApAVCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZrxCqKKiQuPGjVNmZqays7M1a9Ysvf/++3H7zJs3T4FAIG6ZMGFCUpsGAPQNXiFUW1ur0tJS7dq1S9XV1Tpx4oSKiorU3t4et9+MGTPU2NgYWzZv3pzUpgEAfcNAn53feOONuNdr1qxRdna29u7dqylTpsTWB4NBhcPh5HQIAOizLuieUGtrqyRp2LBhcetramqUnZ2tq6++WvPnz1dzc/NZf0ZnZ6ei0WjcAgDoHwLOOZdIoXNOt912mz788EPt2LEjtn7Dhg265JJLlJ+fr/r6ej388MM6ceKE9u7dq2Aw2OXnlJeX69FHH+2yvrW1VVlZWYm0BgAwFI1GFQqFvtT7eMIhVFpaqk2bNumtt97SiBEjzrpfY2Oj8vPz9fLLL6ukpKTL9s7OTnV2dsY1n5eXRwgBQJryCSGve0KnLV68WBs3btT27dvPGUCSFIlElJ+fr4MHD3a7PRgMdjtCAgD0fV4h5JzT4sWL9dprr6mmpkYFBQXnrWlpaVFDQ4MikUjCTQIA+iavBxNKS0v1wgsvaP369crMzFRTU5OamprU0dEhSfr444/1wAMP6C9/+YsOHz6smpoazZw5U8OHD9ftt9+ekr8AACB9ed0TCgQC3a5fs2aN5s2bp46ODs2aNUv79u3TRx99pEgkomnTpuknP/mJ8vLyvtQxfP4tEQDQ+6TsntD58iojI0Nbtmzx+ZEAgH6MueMAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYGWjdwJuecJCkajRp3AgBIxOn379Pv5+fS60Kora1NkpSXl2fcCQDgQrS1tSkUCp1zn4D7MlHVgz7//HMdPXpUmZmZCgQCcdui0ajy8vLU0NCgrKwsow7tcR5O4Tycwnk4hfNwSm84D845tbW1KTc3VwMGnPuuT68bCQ0YMEAjRow45z5ZWVn9+iI7jfNwCufhFM7DKZyHU6zPw/lGQKfxYAIAwAwhBAAwk1YhFAwG9cgjjygYDFq3YorzcArn4RTOwymch1PS7Tz0ugcTAAD9R1qNhAAAfQshBAAwQwgBAMwQQgAAM2kVQk8//bQKCgp08cUX67rrrtOOHTusW+pR5eXlCgQCcUs4HLZuK+W2b9+umTNnKjc3V4FAQK+//nrcduecysvLlZubq4yMDE2dOlUHDhywaTaFznce5s2b1+X6mDBhgk2zKVJRUaFx48YpMzNT2dnZmjVrlt5///24ffrD9fBlzkO6XA9pE0IbNmzQkiVLtHz5cu3bt0+TJ09WcXGxjhw5Yt1ajxo1apQaGxtjS11dnXVLKdfe3q6xY8eqqqqq2+0rV65UZWWlqqqqtHv3boXDYd18882xeQj7ivOdB0maMWNG3PWxefPmHuww9Wpra1VaWqpdu3apurpaJ06cUFFRkdrb22P79Ifr4cucBylNrgeXJm644QZ37733xq37+te/7n74wx8addTzHnnkETd27FjrNkxJcq+99lrs9eeff+7C4bB7/PHHY+s+/fRTFwqF3LPPPmvQYc848zw459zcuXPdbbfdZtKPlebmZifJ1dbWOuf67/Vw5nlwLn2uh7QYCR0/flx79+5VUVFR3PqioiLt3LnTqCsbBw8eVG5urgoKCjRnzhwdOnTIuiVT9fX1ampqirs2gsGgbrzxxn53bUhSTU2NsrOzdfXVV2v+/Plqbm62bimlWltbJUnDhg2T1H+vhzPPw2npcD2kRQgdO3ZMJ0+eVE5OTtz6nJwcNTU1GXXV88aPH69169Zpy5YtWr16tZqamlRYWKiWlhbr1syc/u/f368NSSouLtaLL76orVu36oknntDu3bs1ffp0dXZ2WreWEs45lZWVadKkSRo9erSk/nk9dHcepPS5HnrdLNrncuZXOzjnuqzry4qLi2N/HjNmjCZOnKirrrpKa9euVVlZmWFn9vr7tSFJs2fPjv159OjRuv7665Wfn69NmzappKTEsLPUWLRokd5991299dZbXbb1p+vhbOchXa6HtBgJDR8+XBdddFGX32Sam5u7/MbTnwwdOlRjxozRwYMHrVsxc/rpQK6NriKRiPLz8/vk9bF48WJt3LhR27Zti/vql/52PZztPHSnt14PaRFCgwcP1nXXXafq6uq49dXV1SosLDTqyl5nZ6fee+89RSIR61bMFBQUKBwOx10bx48fV21tbb++NiSppaVFDQ0Nfer6cM5p0aJFevXVV7V161YVFBTEbe8v18P5zkN3eu31YPhQhJeXX37ZDRo0yD3//PPuH//4h1uyZIkbOnSoO3z4sHVrPWbp0qWupqbGHTp0yO3atcvdeuutLjMzs8+fg7a2Nrdv3z63b98+J8lVVla6ffv2uf/85z/OOecef/xxFwqF3Kuvvurq6urcnXfe6SKRiItGo8adJ9e5zkNbW5tbunSp27lzp6uvr3fbtm1zEydOdF/5ylf61Hm47777XCgUcjU1Na6xsTG2fPLJJ7F9+sP1cL7zkE7XQ9qEkHPO/epXv3L5+flu8ODB7tprr417HLE/mD17totEIm7QoEEuNzfXlZSUuAMHDli3lXLbtm1zkrosc+fOdc6deiz3kUceceFw2AWDQTdlyhRXV1dn23QKnOs8fPLJJ66oqMhdfvnlbtCgQe6KK65wc+fOdUeOHLFuO6m6+/tLcmvWrInt0x+uh/Odh3S6HvgqBwCAmbS4JwQA6JsIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCY+T/EhZa/LqOG0gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 6\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 1\n"
     ]
    }
   ],
   "source": [
    "plot_digit(X_train,y_train,100)\n",
    "plot_digit(X_test,y_test,40000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run SVM with 5-fold cross validation to pick the best kernel and values of parameters. We provide some potential choice for parameters, but change the grid if needed (e.g., it takes too long). For the SVM for classification use SVC from sklearn.svm; for the grid search we suggest you use GridSearchCV from sklearn.model_selection, but you can implement your own cross-validation for model selection if you prefer.\n",
    "\n",
    "Finally, print the best parameters used as well as the score obtained by the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LINEAR MODEL:\n",
      "Best parameters set found:\n",
      "{'C': 1}\n",
      "Score with best parameters:\n",
      "0.8300000000000001\n",
      "\n",
      "All scores on the grid:\n",
      "[0.83 0.83 0.83]\n",
      "\n",
      "RESULTS FOR POLY DEGREE=2 KERNEL\n",
      "\n",
      "Best parameters set found:\n",
      "{'C': 1, 'gamma': 0.1}\n",
      "Score with best parameters:\n",
      "0.852\n",
      "\n",
      "All scores on the grid:\n",
      "[0.816 0.852 0.852 0.848 0.852 0.852 0.852 0.852 0.852]\n",
      "\n",
      "RESULTS FOR rbf KERNEL\n",
      "\n",
      "Best parameters set found:\n",
      "{'C': 10, 'gamma': 0.01}\n",
      "Score with best parameters:\n",
      "0.8619999999999999\n",
      "\n",
      "All scores on the grid:\n",
      "[0.854 0.532 0.11  0.862 0.572 0.11  0.862 0.572 0.11 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# parameters for linear SVM\n",
    "parameters = {'C': [1, 10, 100]}\n",
    "\n",
    "#run linear SVM\n",
    "linear_SVM = SVC(kernel='linear')\n",
    "\n",
    "proc = GridSearchCV(linear_SVM, parameters, cv=5)\n",
    "proc.fit(X_train, y_train)\n",
    "\n",
    "print(\"RESULTS FOR LINEAR MODEL:\")\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "print(proc.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "print(proc.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "means = proc.cv_results_['mean_test_score']\n",
    "print(means)\n",
    "\n",
    "# parameters for poly with degree 2 kernel\n",
    "parameters2 = {'C': [1, 10, 100],'gamma':[0.01,0.1,1.]}\n",
    "\n",
    "#run SVM with poly of degree 2 kernel\n",
    "poly2_SVM = SVC(kernel='poly',degree=2)\n",
    "\n",
    "proc2 = GridSearchCV(poly2_SVM, parameters2, cv=5)\n",
    "proc2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print ('\\nRESULTS FOR POLY DEGREE=2 KERNEL\\n')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "print(proc2.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "print(proc2.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "means = proc2.cv_results_['mean_test_score']\n",
    "print(means)\n",
    "\n",
    "# parameters for rbf SVM\n",
    "parameters3 = {'C': [1, 10, 100],'gamma':[0.01,0.1,1.]}\n",
    "\n",
    "#run SVM with rbf kernel\n",
    "rbf_SVM = SVC(kernel='rbf')\n",
    "\n",
    "proc3 = GridSearchCV(rbf_SVM, parameters3, cv=5)\n",
    "proc3.fit(X_train, y_train)\n",
    "\n",
    "print ('\\nRESULTS FOR rbf KERNEL\\n')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "print(proc3.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "print(proc3.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "means = proc3.cv_results_['mean_test_score']\n",
    "print(means)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the \"best\" SVM kernel and choice of parameters from above, train the model on the entire training set and measure the training error. Also make predictions on the test set and measure the test error. Print the training and the test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM training error: 0.016000\n",
      "Best SVM test error: 0.116734\n"
     ]
    }
   ],
   "source": [
    "#get training and test error for the best SVM model from CV\n",
    "best_SVM = SVC(kernel='rbf')\n",
    "\n",
    "# fit the model on the entire training set\n",
    "# ADD CODE\n",
    "best_SVM.fit(X_train, y_train)\n",
    "\n",
    "#get the training and test error\n",
    "training_error = 1. - best_SVM.score(X_train,y_train)\n",
    "test_error = 1. - best_SVM.score(X_test,y_test)\n",
    "\n",
    "print (\"Best SVM training error: %f\" % training_error)\n",
    "print (\"Best SVM test error: %f\" % test_error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use logistic regression for comparison\n",
    "\n",
    "Just for comparison let's also use logistic regression, first with the default values of the parameter for regularization and then with cross-validation to fix the value of the parameters. For cross validation, use 5-fold cross validation and the default values of the regularization parameters for the function linear_model.LogisticRegressionCV(...).\n",
    "\n",
    "Note: during training you may receive a \"ConvergenceWarning\" that indicates that the logistic regression solver did not converge to the optimal result. Given the scope of the notebook, we can ignore such warning but in real-world scenarios you should take corrective measures such as increasing the number of training iterations and/or the runtime for training or picking a different optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucaatme/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best logistic regression training error: 0.000000\n",
      "Best logistic regression test error: 0.162115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucaatme/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/lucaatme/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/lucaatme/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/lucaatme/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/lucaatme/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best logistic regression training error with CV: 0.050000\n",
      "Best logistic regression test error with CV: 0.161165\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "lr = linear_model.LogisticRegression()\n",
    "# fit the model on the training data\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#compute training and test error for model above\n",
    "training_error = 1. - lr.score(X_train,y_train)\n",
    "test_error = 1. - lr.score(X_test,y_test)\n",
    "\n",
    "print (\"Best logistic regression training error: %f\" % training_error)\n",
    "print (\"Best logistic regression test error: %f\" % test_error)\n",
    "\n",
    "#logistic regression with 5-fold CV: you can use use linear_model.LogisticRegressionCV\n",
    "# use 5-fold CV to find the best choice of the parameter, than train\n",
    "# the model on the entire training set\n",
    "lr_cv = linear_model.LogisticRegressionCV(cv=5)\n",
    "lr_cv.fit(X_train, y_train)\n",
    "training_error_cv = 1. - lr_cv.score(X_train,y_train)\n",
    "test_error_cv = 1. - lr_cv.score(X_test,y_test)\n",
    "\n",
    "print (\"Best logistic regression training error with CV: %f\" % training_error_cv)\n",
    "print (\"Best logistic regression test error with CV: %f\" % test_error_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the Logistic Regression and SVM methods are used for the purpose of classification, but the approach is completely different. The former is performing the classification operation based on a probabilistic function, so the classification as 0/1 (or -1/1) takes place as long as the model is confident enough to perform that operation; on the other hand, the second method consists in dividing the n-dimensional space with an halfspace of dimension n-1 to separate the data in the two classes by picking the best possible distinguisher. \n",
    "\n",
    "All of this allows us to comprehend better the results we got: being more \"abstract\", the SVM model is able to generalize the classification operation better than the Logistic Regression one, which on the other hand is more directly dependent from the training data itself and therefore more prone to overfitting. And all of this can be seen from the results; the SVM model has an higher training error than the Logistic Regression method's one, meaning that it is not able to perfectly fit the training data, but it is able to generalize better on the test data, which is the goal of the classification operation. The Logistic Regression method on the other hand is perfectly able to classify the training data, but it is not able to generalize well on the test data, as it's test error is higher than the one of the SVM model.\n",
    "\n",
    "**small comment regarding the results of SVM kernel**: according to the scores, it turns out that the *rbf* kernel was the more appropriate choice for the SVM model. This makes sense, as the MNIST dataset would require the classification of the not-so-easily-distinguishable elements in 10 classes (instead of just 2), so it's more likely for non-linear decision boundaries (obtained with the *rbf* kernel) to better differentiate the classes than a simple, linear kernel."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's now see an element that gets missclassified by the logistic regression model and gets correctly classified by the SVM one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 8\n",
      "Logistic regression prediction: ['9']\n",
      "SVM prediction: ['8']\n"
     ]
    }
   ],
   "source": [
    "missclassified_index = 0\n",
    "for i in range(len(y_test)):\n",
    "    if lr.predict(X_test[i].reshape(1,-1)) != y_test[i] and best_SVM.predict(X_test[i].reshape(1,-1)) == y_test[i] :\n",
    "        missclassified_index = i\n",
    "        break\n",
    "\n",
    "#plot the element\n",
    "plot_digit(X_test,y_test,missclassified_index)\n",
    "\n",
    "#label predicted by logistic regression\n",
    "print(\"Logistic regression prediction: %s\" % lr.predict(X_test[missclassified_index].reshape(1,-1)))\n",
    "#label predicted by SVM\n",
    "print(\"SVM prediction: %s\" % best_SVM.predict(X_test[missclassified_index].reshape(1,-1)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More data\n",
    "Now let's do the same but using 1000 data points for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and frequencies in training dataset: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype=object),\n",
       " array([107, 117,  88, 105, 104,  84, 104,  92, 108,  91]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag = False\n",
    "\n",
    "while not flag:\n",
    "\n",
    "    permutation = np.random.permutation(X.shape[0])\n",
    "\n",
    "    X = X[permutation]\n",
    "    y = y[permutation]\n",
    "\n",
    "    m_training = 1000\n",
    "\n",
    "    X_train, X_test = X[:m_training], X[m_training:]\n",
    "    y_train, y_test = y[:m_training], y[m_training:]\n",
    "    \n",
    "    for i in range(10):\n",
    "        if np.count_nonzero(y_train == str(i)) >= 10:\n",
    "            flag = True\n",
    "\n",
    "print(\"Labels and frequencies in training dataset: \")\n",
    "np.unique(y_train, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LINEAR MODEL:\n",
      "Best parameters set found:\n",
      "{'C': 1}\n",
      "Score with best parameters:\n",
      "0.891\n",
      "\n",
      "All scores on the grid:\n",
      "[0.891 0.891 0.891]\n",
      "\n",
      "RESULTS FOR POLY DEGREE=2 KERNEL\n",
      "\n",
      "Best parameters set found:\n",
      "{'C': 10, 'gamma': 0.01}\n",
      "Score with best parameters:\n",
      "0.9179999999999999\n",
      "\n",
      "All scores on the grid:\n",
      "[0.876 0.917 0.917 0.918 0.917 0.917 0.917 0.917 0.917]\n",
      "\n",
      "RESULTS FOR rbf KERNEL\n",
      "\n",
      "Best parameters set found:\n",
      "{'C': 10, 'gamma': 0.01}\n",
      "Score with best parameters:\n",
      "0.929\n",
      "\n",
      "All scores on the grid:\n",
      "[0.91  0.614 0.117 0.929 0.641 0.117 0.929 0.641 0.117]\n"
     ]
    }
   ],
   "source": [
    "# parameters for linear SVM\n",
    "parameters = {'C': [1, 10, 100]}\n",
    "\n",
    "#run linear SVM\n",
    "linear_SVM = SVC(kernel='linear')\n",
    "\n",
    "proc = GridSearchCV(linear_SVM, parameters, cv=5)\n",
    "proc.fit(X_train, y_train)\n",
    "\n",
    "print(\"RESULTS FOR LINEAR MODEL:\")\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "print(proc.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "print(proc.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "means = proc.cv_results_['mean_test_score']\n",
    "print(means)\n",
    "\n",
    "# parameters for poly with degree 2 kernel\n",
    "parameters2 = {'C': [1, 10, 100],'gamma':[0.01,0.1,1.]}\n",
    "\n",
    "#run SVM with poly of degree 2 kernel\n",
    "poly2_SVM = SVC(kernel='poly',degree=2)\n",
    "\n",
    "# SAME AS ABOVE FOR POLYNOMIAL KERNEL WITH DEGREE=2\n",
    "\n",
    "proc2 = GridSearchCV(poly2_SVM, parameters2, cv=5)\n",
    "proc2.fit(X_train, y_train)\n",
    "\n",
    "print ('\\nRESULTS FOR POLY DEGREE=2 KERNEL\\n')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "print(proc2.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "print(proc2.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "means = proc2.cv_results_['mean_test_score']\n",
    "print(means)\n",
    "\n",
    "# parameters for rbf SVM\n",
    "parameters3 = {'C': [1, 10, 100],'gamma':[0.01,0.1,1.]}\n",
    "\n",
    "#run SVM with rbf kernel\n",
    "rbf_SVM = SVC(kernel='rbf')\n",
    "\n",
    "# SAME AS ABOVE FOR RBF KERNEL\n",
    "proc3 = GridSearchCV(rbf_SVM, parameters3, cv=5)\n",
    "proc3.fit(X_train, y_train)\n",
    "\n",
    "print ('\\nRESULTS FOR rbf KERNEL\\n')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "print(proc3.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "print(proc3.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "means = proc3.cv_results_['mean_test_score']\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM training error: 0.014000\n",
      "Best SVM test error: 0.081971\n"
     ]
    }
   ],
   "source": [
    "#get training and test error for the best SVM model from CV\n",
    "best_SVM = SVC(kernel='rbf')\n",
    "\n",
    "# fit the model on the entire training set\n",
    "best_SVM.fit(X_train, y_train)\n",
    "\n",
    "#get the training and test error\n",
    "training_error = 1. - best_SVM.score(X_train,y_train)\n",
    "test_error = 1. - best_SVM.score(X_test,y_test)\n",
    "\n",
    "print (\"Best SVM training error: %f\" % training_error)\n",
    "print (\"Best SVM test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucaatme/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best logistic regression training error: 0.000000\n",
      "Best logistic regression test error: 0.130594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucaatme/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/lucaatme/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/lucaatme/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/lucaatme/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/lucaatme/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best logistic regression training error with CV: 0.000000\n",
      "Best logistic regression test error with CV: 0.133232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucaatme/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "lr = linear_model.LogisticRegression()\n",
    "# fit the model on the training data\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#compute training and test error for model above\n",
    "training_error = 1. - lr.score(X_train,y_train)\n",
    "test_error = 1. - lr.score(X_test,y_test)\n",
    "\n",
    "print (\"Best logistic regression training error: %f\" % training_error)\n",
    "print (\"Best logistic regression test error: %f\" % test_error)\n",
    "\n",
    "# logistic regression with 5-fold CV: you can use use linear_model.LogisticRegressionCV\n",
    "# use 5-fold CV to find the best choice of the parameter, than train\n",
    "# the model on the entire training set\n",
    "lr_cv = linear_model.LogisticRegressionCV(cv=5)\n",
    "lr_cv.fit(X_train, y_train)\n",
    "training_error_cv = 1. - lr_cv.score(X_train,y_train)\n",
    "test_error_cv = 1. - lr_cv.score(X_test,y_test)\n",
    "\n",
    "print (\"Best logistic regression training error with CV: %f\" % training_error_cv)\n",
    "print (\"Best logistic regression test error with CV: %f\" % test_error_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 5\n",
      "Logistic regression prediction: ['8']\n",
      "SVM prediction: ['5']\n"
     ]
    }
   ],
   "source": [
    "#find an element in the test set that is missclassified by logistic regression\n",
    "\n",
    "missclassified_index = 0\n",
    "for i in range(len(y_test)):\n",
    "    if lr.predict(X_test[i].reshape(1,-1)) != y_test[i] and best_SVM.predict(X_test[i].reshape(1,-1)) == y_test[i] :\n",
    "    #if best_SVM.predict(X_test[i].reshape(1,-1)) != y_test[i]:\n",
    "        missclassified_index = i\n",
    "        break\n",
    "\n",
    "#plot the element\n",
    "plot_digit(X_test,y_test,missclassified_index)\n",
    "\n",
    "#label predicted by logistic regression\n",
    "print(\"Logistic regression prediction: %s\" % lr.predict(X_test[missclassified_index].reshape(1,-1)))\n",
    "#label predicted by SVM\n",
    "print(\"SVM prediction: %s\" % best_SVM.predict(X_test[missclassified_index].reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous training with 500 samples the Logistic Regression model led to a training error equal to zero, meaning there was overfitting as the difference between training and test error was quite evident. At the same time the results obtained with either one of the two methods were quite good, so doubling the size of the training set could additionally increase the performance or introduce some overfitting.\n",
    "\n",
    "Let's have a look at what happened at the SVM model: the value of the training error has slightly increased, meaning that our model is abstracting a little bit more from the training set; we also have a smaller test error, an indication that the model is now able to perform better in a generic scenario. \n",
    "The same thing happens to the Logistic Regression model: the version using 5-fold cross validation no longer has a training error of 0 but the test error has decreased of almost 2 points; the version of LR without folds is performing better too, by keeping 0% as training error and a test error of 13.18 against the 14.58 of the previous model (training set of size 500). We can then say that adding those 500 elements to the training set is increasing the performance of the model afterall, and it is doing all of this without compromising the computational costs. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d8bd18ad22f2a29ef9669f9dec08ffee36a51f0a7d945611c3a5228678b33a78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
